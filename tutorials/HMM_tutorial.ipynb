{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blechpy Poisson HMM Tutorial\n",
    "This tutorial will cover how to setup and fit spike data to a poisson HMM.\n",
    "To use this you must first already have a blechpy.dataset object created with data that is past the spike sorting stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import blechpy\n",
    "from blechpy.analysis import poissonHMM as phmm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the path to your recording folder\n",
    "rec_dir = '/data/Katz_Data/Stk11_Project/RN10/RN10_ctaTest_190220_131512'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a single HMM\n",
    "To fit a single HMM you will using the PoissonHMM object. This object will house all the necessary parameters for an HMM except for the data being fitted. \n",
    "### Gathering the data\n",
    "First you will need to collect the data for the HMM to fit. This should be a spike array (numpy array, dtype=int32) with 3-dimensions: Trial, Cell, Time bin with each value being the number of spikes in the time bin. If you have sorted your units and then used dat.make_unit_arrays(), then your spike arrays are stored in you h5 file with 1ms time bins from -2000 ms to 5000 ms. You will need to grab this spike array and cut it down to the right time window that you want to model as well as only the units you want to use. Additionally, you may need to rebin this array to have a different time step (especially with sparse firing units). \n",
    "\n",
    "phmm has a useful function for gathering this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "din_channel = 0 # Channel of the digital input that the trials you wish to fit are on\n",
    "unit_type = 'single' # This can be single (for all single units),\n",
    "                     # pyramidal (only single unit regular-spiking cells) \n",
    "                     # or interneuron (only single unit fast-spiking cells)\n",
    "        \n",
    "# The parameters below are optional\n",
    "time_start = 0  # Time start in ms\n",
    "time_end = 2000 # Time end in ms\n",
    "dt = 0.01 # desired bin size for the return spike array in seconds, default is 0.001 seconds\n",
    "\n",
    "spike_array, dt, time = phmm.get_hmm_spike_data(rec_dir, unit_type, din_channel, time_start, time_end, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and fitting the model\n",
    "Now you can go ahead and initialize and fit your HMM.\n",
    "#### Something to note: \n",
    "I have not yet figured out the best parameters to use to test convergence. So for now at each iteration the changes in every matrix (transition, emission and initial distribution) are computed and when the total change in every matrix is below the threshold then fitting stops. Alternatively, fitting stops if the maximum number of iterations is reached. For now the default convergence threshold is 1e-4 which works well for the simulated data. I have not yet had actual data meet this criteria. \n",
    "\n",
    "Also the cost of the model is computed on each iteration. The cost is computed by predicting the state at each time point and then using the emission (rate) matrix to predict the firing rate in each bin and them computing the distance of this prediction from the actual firing rate. This is then summed over time bins and averaged over trials to get the final cost of the model. This would probably provide a better measure of convergence, but I have not yet determined the best threshold for change in cost at which to stop fitting. Also this may lead to overfitting. But cost does provide a means of comparing models since BIC is only a good measure to compare models with the same number of states and time bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 3  # Number of predicted states in your data\n",
    "cost_window = 0.25 # Size of the window with which to compute the cost function in seconds\n",
    "                   # The cost of a model is computed by predicting the firing rate of each\n",
    "                   # neuron in each bin and comparing it to the actual data. The cost is\n",
    "                   # currently the average euclidean distance of the prediction from the actual. \n",
    "                   # Averaged over trials\n",
    "                   # This is optional: default is 0.25 seconds\n",
    "                   # Right now the cost is only used for your own evaluation of how good your model fits the data\n",
    "\n",
    "# Initializing the model\n",
    "model = phmm.PoissonHMM(n_states, cost_window=cost_window) # Notice you're not giving it the data yet\n",
    "\n",
    "# Fitting the model\n",
    "convergence_threshold = 1e-4  # This is optional and this number is based on nothing\n",
    "                              # So far this works well for fitting simulated data,\n",
    "                              # But I have not yet seen actual data meet this criteria\n",
    "max_iter = 1000  # This is also optional, the default is 1000\n",
    "\n",
    "model.fit(spike_array, dt, max_iter=max_iter, convergence_thresh=convergence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding your model\n",
    "Now that the model is fitted there are some useful aspects to know about it. \n",
    "#### Important Attributes\n",
    "- model.transition\n",
    " - transtion matrix giving probability of switching from one state to another\n",
    "- model.emission\n",
    " - This is actually a rate matrix expressing the predicted firing of each neuron in each state\n",
    "- model.initial_distribution\n",
    " - This gives the probability of being in each state at the start\n",
    "- model.cost\n",
    " - This has the last computed cost of the model\n",
    "- model.BIC\n",
    " - This has the last computed Bayesian Information Criteria of the model\n",
    "- model.best_sequences\n",
    " - This has the best predicted sequence for each trial\n",
    "- model.max_log_prob\n",
    " - Max log probability of the sequences (not sure this is computed correctly)\n",
    " \n",
    "#### Useful fucntions in the model\n",
    "     best_sequences, max_log_prob = model.get_best_paths(spike_array, dt)\n",
    "     forward_probs = model.get_forward_probabilities(spike_array, dt)\n",
    "     bakward_probs = model.get_backward_probabilities(spike_array, dt)\n",
    "     gamma_probs = model.get_gamma_probabilites(spike_array, dt)\n",
    "     \n",
    "Additionally the model keeps a limited history of previous iterations can be be rolled back in case you pass a minima. Use:\n",
    "    `model.set_to_lowest_cost()`\n",
    "    or\n",
    "    `model.set_to_lowest_BIC()`\n",
    "     \n",
    "Finally if you would like to re-fit the model, be sure to randomize it again before refitting:\n",
    "- `model.randomize(spike_array, dt)`\n",
    "- `model.fit(spike_array, dt)`\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and saving HMMs\n",
    "That's just a breakdown of a `PoissonHMM` object. A much better way is to use the `HmmHandler`. This interface handles fitting HMMs for all digital inputs (tastes) as well as trying different parameters sets, plotting and saving all data to an hdf5 store. *This store is seperate from your data h5 file*\n",
    "The HMM handler also takes care of parallelizing HMM fitting and creating plots for fitted HMMs\n",
    "\n",
    "### The Parameters\n",
    "\n",
    "The HmmHandler is passed parameters as a dict or a list of dicts. You can provide as many or as few of these parameters as you want. The defaults are drawn from `phmm.HMM_PARAMS`. These important parameters are:\n",
    "- hmm_id\n",
    " - This is set automatically by the handler\n",
    "- taste\n",
    " - This will be set automatically as all tastes in the dataset, but you can specific a single one if you'd like\n",
    "- channel\n",
    " - This is always set automatically\n",
    "- unit_type\n",
    " - can be 'single', 'pyramidal', or 'interneurons'\n",
    "- dt\n",
    " - time bin size to use in seconds\n",
    "- threshold\n",
    " - the convergence threshold to use for fitting\n",
    "- max_iter\n",
    " - max number of iterations while fitting\n",
    "- n_cells\n",
    " - Set automatically\n",
    "- n_trials\n",
    " - Set automatically\n",
    "- time_start\n",
    " - Time start to cut data\n",
    "- time_end\n",
    " - Time end to cut data\n",
    "- n_repeats\n",
    " - Number of repeats to fit of this HMM, best is chosen automatically by lowest BIC\n",
    "- n_states\n",
    " - Number of predicted states to fit\n",
    "- fitted\n",
    " - set automatically when fitting is compelete\n",
    " \n",
    "Notice that a lot are set automatically, so your input dict can only contain the parameters you want to deviate from the defaults, the rest will be filled in. See the below cell's output to see the default dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hmm_id': None,\n",
       " 'taste': None,\n",
       " 'channel': None,\n",
       " 'unit_type': 'single',\n",
       " 'dt': 0.001,\n",
       " 'threshold': 0.0001,\n",
       " 'max_iter': 1000,\n",
       " 'n_cells': None,\n",
       " 'n_trials': None,\n",
       " 'time_start': 0,\n",
       " 'time_end': 2000,\n",
       " 'n_repeats': 3,\n",
       " 'n_states': 3,\n",
       " 'fitted': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phmm.HMM_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'unit_type': 'pyramidal', 'time_end': 2500, 'n_states': 2}, {'unit_type': 'pyramidal', 'time_end': 2500, 'n_states': 3}]\n"
     ]
    }
   ],
   "source": [
    "# Example of defining parameter set\n",
    "params = [{'unit_type': 'pyramidal', 'time_end': 2500, 'n_states': x} for x in [2,3]]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can initialize and run the handler\n",
    "Keep in mind after using the handler you can load it again at anytime and add new parameters and re-run, only the model that haven't already been fitted will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "handler = phmm.HmmHandler(rec_dir)\n",
    "# Save directory is automatically made inside the recording directory,\n",
    "# but you can also specificy another place witht eh save_dir keyword argument.\n",
    "# You can also pass the params directly when initializing the handler, but\n",
    "# I just split it here you can see how to add new parameters later.\n",
    "handler.add_params(params)\n",
    "\n",
    "# Running the handler\n",
    "handler.run() # to overwrite existing models pass overwrite=True\n",
    "\n",
    "# Looking at the parameters already in the handler\n",
    "parameter_overview = handler.get_parameter_overview() # this is a pandas DataFrame\n",
    "\n",
    "# Looking at the parameters and fitted model stats\n",
    "data_overview = handler.get_data_overview() # also a pandas DataFrame with extra info such as cost and BIC\n",
    "\n",
    "# The matrices defining each HMM and the best sequences can be access from teh HDF5 store directly. They can also be access programatically with:\n",
    "hdf5_file = handler.h5_file\n",
    "hmm, time, params = handler.get_hmm(0) # the hmm_id number goes here\n",
    "# The hmm object has an attribute stat_arrays with various information including best_sequences, \n",
    "# gamma_probabilities, max_log_prob (on each iteration), time, and row_id\n",
    "# Now you have the PoissonHMM object with the fitted model parameters and can do anything with it. \n",
    "# Only information lost is the model history, every model is set to the best model in the history before saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
