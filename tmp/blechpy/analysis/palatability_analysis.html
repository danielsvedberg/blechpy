<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>blechpy.analysis.palatability_analysis API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>blechpy.analysis.palatability_analysis</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from blechpy.datastructures.objects import load_dataset
from blechpy.dio import h5io
from blechpy.utils import print_tools as pt, userIO
import numpy as np
import pandas as pd
import tables
from scipy.stats import f_oneway, ttest_ind, spearmanr, pearsonr, rankdata
from scipy.spatial.distance import cdist
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.model_selection import LeavePOut, StratifiedShuffleSplit
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LinearRegression
from sklearn.isotonic import IsotonicRegression
import os
import itertools
import warnings



default_pal_id_params ={&#39;window_size&#39;: 250, &#39;window_step&#39;: 25,
                        &#39;num_comparison_bins&#39;: 5, &#39;comparison_bin_size&#39;: 250,
                        &#39;discrim_p&#39;: 0.01, &#39;pal_deduce_start_time&#39;: 700,
                        &#39;pal_deduce_end_time&#39;: 1200, &#39;unit_type&#39;: &#39;Single&#39;}

def palatability_identity_calculations(rec_dir, pal_ranks=None,
                                       params=None, shell=False):
    warnings.filterwarnings(&#39;ignore&#39;, category=UserWarning)
    warnings.filterwarnings(&#39;ignore&#39;, category=RuntimeWarning)
    dat = load_dataset(rec_dir)
    dim = dat.dig_in_mapping
    if &#39;palatability_rank&#39; in dim.columns:
        pass
    elif pal_ranks is None:
        dim = get_palatability_ranks(dim, shell=shell)
    else:
        dim[&#39;palatability_rank&#39;] = dim[&#39;name&#39;].map(pal_ranks)

    dim = dim.dropna(subset=[&#39;palatability_rank&#39;])
    dim = dim[dim[&#39;palatability_rank&#39;] &gt; 0]
    dim = dim.reset_index(drop=True)
    num_tastes = len(dim)
    taste_names = dim.name.to_list()

    trial_list = dat.dig_in_trials.copy()
    trial_list = trial_list[[True if x in taste_names else False
                             for x in trial_list.name]]
    num_trials = trial_list.groupby(&#39;channel&#39;).count()[&#39;name&#39;].unique()
    if len(num_trials) &gt; 1:
        raise ValueError(&#39;Unequal number of trials for tastes to used&#39;)
    else:
        num_trials = num_trials[0]

    dim[&#39;num_trials&#39;] = num_trials

    # Get which units to use
    unit_table = h5io.get_unit_table(rec_dir)
    unit_types = [&#39;Single&#39;, &#39;Multi&#39;, &#39;All&#39;, &#39;Custom&#39;]
    unit_type = params.get(&#39;unit_type&#39;)
    if unit_type is None:
        q = userIO.ask_user(&#39;Which units do you want to use for taste &#39;
                            &#39;discrimination and  palatability analysis?&#39;,
                            choices=unit_types,
                            shell=shell)
        unit_type = unit_types[q]

    if unit_type == &#39;Single&#39;:
        chosen_units = unit_table.loc[unit_table[&#39;single_unit&#39;],
                                      &#39;unit_num&#39;].to_list()
    elif unit_type == &#39;Multi&#39;:
        chosen_units = unit_table.loc[unit_table[&#39;single_unit&#39;] == False,
                                      &#39;unit_num&#39;].to_list()
    elif unit_type == &#39;All&#39;:
        chosen_units = unit_table[&#39;unit_num&#39;].to_list()
    else:
        selection = userIO.select_from_list(&#39;Select units to use:&#39;,
                                            unit_table[&#39;unit_num&#39;],
                                            &#39;Select Units&#39;,
                                            multi_select=True)
        chosen_units = list(map(int, selection))

    num_units = len(chosen_units)
    unit_table = unit_table.loc[chosen_units]

    # Enter Parameters
    if params is None or params.keys() != default_pal_id_params.keys():
        params = default_pal_id_params.copy()
        params = userIO.confirm_parameter_dict(params,
                                               (&#39;Palatability/Identity &#39;
                                                &#39;Calculation Parameters&#39;
                                                &#39;\nTimes in ms&#39;), shell=shell)

    win_size = params[&#39;window_size&#39;]
    win_step = params[&#39;window_step&#39;]
    print(&#39;Running palatability/identity calculations with parameters:\n%s&#39; %
          pt.print_dict(params))

    with tables.open_file(dat.h5_file, &#39;r+&#39;) as hf5:
        trains_dig_in = hf5.list_nodes(&#39;/spike_trains&#39;)
        time = trains_dig_in[0].array_time[:]
        bin_times = np.arange(time[0], time[-1] - win_size + win_step,
                             win_step)
        num_bins = len(bin_times)

        palatability = np.empty((num_bins, num_units, num_tastes*num_trials),
                                dtype=int)
        identity = np.empty((num_bins, num_units, num_tastes*num_trials),
                            dtype=int)
        unscaled_response = np.empty((num_bins, num_units, num_tastes*num_trials),
                                     dtype=np.dtype(&#39;float64&#39;))
        response  = np.empty((num_bins, num_units, num_tastes*num_trials),
                             dtype=np.dtype(&#39;float64&#39;))
        laser = np.empty((num_bins, num_units, num_tastes*num_trials, 2),
                         dtype=float)

        # Fill arrays with data
        print(&#39;Filling data arrays...&#39;)
        onesies = np.ones((num_bins, num_units, num_trials))
        for i, row in dim.iterrows():
            idx = range(num_trials*i, num_trials*(i+1))
            palatability[:, :, idx] = row.palatability_rank * onesies
            identity[:, :, idx] = row.channel * onesies
            for j, u in enumerate(chosen_units):
                for k,t in enumerate(bin_times):
                    t_idx = np.where((time &gt;= t) &amp; (time &lt;= t+win_size))[0]
                    unscaled_response[k, j, idx] = \
                            np.mean(trains_dig_in[i].spike_array[:, u, t_idx],
                                    axis=1)
                    try:
                        lasers[k, j, idx] = \
                            np.vstack((trains_dig_in[i].laser_durations[:],
                                       trains_dig_in[i].laser_onset_lag[:]))
                    except:
                        laser[k, j, idx] = np.zeros((num_trials, 2))

        # Scaling was not done, so:
        response = unscaled_response.copy()

        # Make ancillary_analysis node and put in arrays
        if &#39;/ancillary_analysis&#39; in hf5:
            hf5.remove_node(&#39;/ancillary_analysis&#39;, recursive=True)

        hf5.create_group(&#39;/&#39;, &#39;ancillary_analysis&#39;)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;palatability&#39;, palatability)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;identity&#39;, identity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;laser&#39;, laser)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;scaled_neural_response&#39;,
                         response)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;window_params&#39;,
                         np.array([win_size, win_step]))
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;bin_times&#39;, bin_times)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;unscaled_neural_response&#39;,
                         unscaled_response)

        # for backwards compatibility
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;params&#39;,
                        np.array([win_size, win_step]))
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;pre_stim&#39;, np.array(time[0]))
        hf5.flush()

        # Get unique laser (duration, lag) combinations
        print(&#39;Organizing trial data...&#39;)
        unique_lasers = np.vstack(list({tuple(row) for row in laser[0, 0, :, :]}))
        unique_lasers = unique_lasers[unique_lasers[:, 1].argsort(), :]
        num_conditions = unique_lasers.shape[0]
        trials = []
        for row in unique_lasers:
            tmp_trials = [j for j in range(num_trials * num_tastes)
                          if np.array_equal(laser[0, 0, j, :], row)]
            trials.append(tmp_trials)

        trials_per_condition = [len(x) for x in trials]
        if not all(x == trials_per_condition[0] for x in trials_per_condition):
            raise ValueError(&#39;Different number of trials for each laser condition&#39;)

        trials_per_condition = int(trials_per_condition[0] / num_tastes)  #assumes same number of trials per taste per condition
        print(&#39;Detected:\n    %i tastes\n    %i laser conditions\n&#39;
              &#39;    %i trials per condition per taste&#39; %
              (num_tastes, num_conditions, trials_per_condition))
        trials = np.array(trials)

        # Store laser conditions and indices of trials per condition in trial x
        # taste space
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;trials&#39;, trials)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;laser_combination_d_l&#39;,
                         unique_lasers)
        hf5.flush()

        # Taste Similarity Calculation
        neural_response_laser = np.empty((num_conditions, num_bins,
                                          num_tastes, num_units,
                                          trials_per_condition),
                                         dtype=np.dtype(&#39;float64&#39;))
        taste_cosine_similarity = np.empty((num_conditions, num_bins,
                                            num_tastes, num_tastes),
                                           dtype=np.dtype(&#39;float64&#39;))
        taste_euclidean_distance = np.empty((num_conditions, num_bins,
                                             num_tastes, num_tastes),
                                            dtype=np.dtype(&#39;float64&#39;))

        # Re-format neural responses from bin x unit x (trial*taste) to
        # laser_condition x bin x taste x unit x trial
        print(&#39;Reformatting data arrays...&#39;)
        for i, trial in enumerate(trials):
            for j, _ in enumerate(bin_times):
                for k, _ in dim.iterrows():
                    idx = np.where((trial &gt;= num_trials*k) &amp;
                                   (trial &lt; num_trials*(k+1)))[0]
                    neural_response_laser[i, j, k, :, :] = \
                            response[j, :, trial[idx]].T

        # Compute taste cosine similarity and euclidean distances
        print(&#39;Computing taste cosine similarity and euclidean distances...&#39;)
        for i, _ in enumerate(trials):
            for j, _ in enumerate(bin_times):
                for k, _ in dim.iterrows():
                    for l, _ in dim.iterrows():
                        taste_cosine_similarity[i, j, k, l] = \
                                np.mean(cosine_similarity(
                                    neural_response_laser[i, j, k, :, :].T,
                                    neural_response_laser[i, j, l, :, :].T))
                        taste_euclidean_distance[i, j, k, l] = \
                                np.mean(cdist(
                                    neural_response_laser[i, j, k, :, :].T,
                                    neural_response_laser[i, j, l, :, :].T,
                                    metric=&#39;euclidean&#39;))

        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_cosine_similarity&#39;,
                         taste_cosine_similarity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_euclidean_distance&#39;,
                         taste_euclidean_distance)
        hf5.flush()

        # Taste Responsiveness calculations
        bin_params = [params[&#39;num_comparison_bins&#39;],
                      params[&#39;comparison_bin_size&#39;]]
        discrim_p = params[&#39;discrim_p&#39;]

        responsive_neurons = []
        discriminating_neurons = []
        taste_responsiveness = np.zeros((bin_params[0], num_units, 2))
        new_bin_times = np.arange(0, np.prod(bin_params), bin_params[1])
        baseline = np.where(bin_times &lt; 0)[0]
        print(&#39;Computing taste responsiveness and taste discrimination...&#39;)
        for i, t in enumerate(new_bin_times):
            places = np.where((bin_times &gt;= t) &amp;
                              (bin_times &lt;= t+bin_params[1]))[0]
            for j, u in enumerate(chosen_units):
                # Check taste responsiveness
                f, p = f_oneway(np.mean(response[places, j, :], axis=0),
                                np.mean(response[baseline, j, :], axis=0))
                if np.isnan(f):
                    f = 0.0
                    p = 1.0

                if p &lt;= discrim_p and u not in responsive_neurons:
                    responsive_neurons.append(u)
                    taste_responsiveness[i, j, 0] = 1

                # Check taste discrimination
                taste_idx = [np.arange(num_trials*k, num_trials*(k+1))
                             for k in range(num_tastes)]
                taste_responses = [np.mean(response[places, j, :][:, k], axis=0)
                                   for k in taste_idx]
                f, p = f_oneway(*taste_responses)
                if np.isnan(f):
                    f = 0.0
                    p = 1.0

                if p &lt;= discrim_p and u not in discriminating_neurons:
                    discriminating_neurons.append(u)

        responsive_neurons = np.sort(responsive_neurons)
        discriminating_neurons = np.sort(discriminating_neurons)

        # Write taste responsive and taste discriminating units to text file
        save_file = os.path.join(rec_dir, &#39;discriminative_responsive_neurons.txt&#39;)
        with open(save_file, &#39;w&#39;) as f:
            print(&#39;Taste discriminative neurons&#39;, file=f)
            for u in discriminating_neurons:
                print(u, file=f)

            print(&#39;Taste responsive neurons&#39;, file=f)
            for u in responsive_neurons:
                print(u, file=f)

        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_disciminating_neurons&#39;,
                         discriminating_neurons)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_responsive_neurons&#39;,
                         responsive_neurons)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_responsiveness&#39;,
                         taste_responsiveness)
        hf5.flush()

        # Get time course of taste discrimibility
        print(&#39;Getting taste discrimination time course...&#39;)
        p_discrim = np.empty((num_conditions, num_bins, num_tastes, num_tastes,
                              num_units), dtype=np.dtype(&#39;float64&#39;))
        for i in range(num_conditions):
            for j, t in enumerate(bin_times):
                for k in range(num_tastes):
                    for l in range(num_tastes):
                        for m in range(num_units):
                            _, p = ttest_ind(neural_response_laser[i, j, k, m, :],
                                             neural_response_laser[i, j, l, m, :],
                                             equal_var = False)
                            if np.isnan(p):
                                p = 1.0

                            p_discrim[i, j, k, l, m] = p

        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;p_discriminability&#39;,
                          p_discrim)
        hf5.flush()

        # Palatability Rank Order calculation (if &gt; 2 tastes)
        t_start = params[&#39;pal_deduce_start_time&#39;]
        t_end = params[&#39;pal_deduce_end_time&#39;]
        if num_tastes &gt; 2:
            print(&#39;Deducing palatability rank order...&#39;)
            palatability_rank_order_deduction(rec_dir, neural_response_laser,
                                              unique_lasers,
                                              bin_times, [t_start, t_end])

        # Palatability calculation
        r_spearman = np.zeros((num_conditions, num_bins, num_units))
        p_spearman = np.ones((num_conditions, num_bins, num_units))
        r_pearson = np.zeros((num_conditions, num_bins, num_units))
        p_pearson = np.ones((num_conditions, num_bins, num_units))
        f_identity = np.ones((num_conditions, num_bins, num_units))
        p_identity = np.ones((num_conditions, num_bins, num_units))
        lda_palatability = np.zeros((num_conditions, num_bins))
        lda_identity = np.zeros((num_conditions, num_bins))
        r_isotonic = np.zeros((num_conditions, num_bins, num_units))
        id_pal_regress = np.zeros((num_conditions, num_bins, num_units, 2))
        pairwise_identity = np.zeros((num_conditions, num_bins, num_tastes, num_tastes))
        print(&#39;Computing palatability metrics...&#39;)

        for i, t in enumerate(trials):
            for j in range(num_bins):
                for k in range(num_units):
                    ranks = rankdata(response[j, k, t])
                    r_spearman[i, j, k], p_spearman[i, j, k] = \
                            spearmanr(ranks, palatability[j, k, t])
                    r_pearson[i, j, k], p_pearson[i, j, k] = \
                            pearsonr(response[j, k, t], palatability[j, k, t])
                    if np.isnan(r_spearman[i, j, k]):
                        r_spearman[i, j, k] = 0.0
                        p_spearman[i, j, k] = 1.0

                    if np.isnan(r_pearson[i, j, k]):
                        r_pearson[i, j, k] = 0.0
                        p_pearson[i, j, k] = 1.0

                    # Isotonic regression of firing against palatability
                    model = IsotonicRegression(increasing = &#39;auto&#39;)
                    model.fit(palatability[j, k, t], response[j, k, t])
                    r_isotonic[i, j, k] = model.score(palatability[j, k, t],
                                                      response[j, k, t])

                    # Multiple Regression of firing rate against palatability and identity
                    # Regress palatability on identity
                    tmp_id = identity[j, k, t].reshape(-1, 1)
                    tmp_pal = palatability[j, k, t].reshape(-1, 1)
                    tmp_resp = response[j, k, t].reshape(-1, 1)
                    model_pi = LinearRegression()
                    model_pi.fit(tmp_id, tmp_pal)
                    pi_residuals = tmp_pal - model_pi.predict(tmp_id)

                    # Regress identity on palatability
                    model_ip = LinearRegression()
                    model_ip.fit(tmp_pal, tmp_id)
                    ip_residuals = tmp_id - model_ip.predict(tmp_pal)

                    # Regress firing on identity
                    model_fi = LinearRegression()
                    model_fi.fit(tmp_id, tmp_resp)
                    fi_residuals = tmp_resp - model_fi.predict(tmp_id)

                    # Regress firing on palatability
                    model_fp = LinearRegression()
                    model_fp.fit(tmp_pal, tmp_resp)
                    fp_residuals = tmp_resp - model_fp.predict(tmp_pal)

                    # Get partial correlation coefficient of response with identity
                    idp_reg0, p = pearsonr(fp_residuals, ip_residuals)
                    if np.isnan(idp_reg0):
                        idp_reg0 = 0.0

                    idp_reg1, p = pearsonr(fi_residuals, pi_residuals)
                    if np.isnan(idp_reg1):
                        idp_reg1 = 0.0

                    id_pal_regress[i, j, k, 0] = idp_reg0
                    id_pal_regress[i, j, k, 1] = idp_reg1

                    # Identity Calculation
                    samples = []
                    for _, row in dim.iterrows():
                        taste = row.channel
                        samples.append([trial for trial in t
                                        if identity[j, k, trial] == taste])

                    tmp_resp = [response[j, k, sample] for sample in samples]
                    f_identity[i, j, k], p_identity[i, j, k] = f_oneway(*tmp_resp)
                    if np.isnan(f_identity[i, j, k]):
                        f_identity[i, j, k] = 0.0
                        p_identity[i, j, k] = 1.0


                # Linear Discriminant analysis for palatability
                X = response[j, :, t]
                Y = palatability[j, 0, t]
                test_results = []
                c_validator = LeavePOut(1)
                for train, test in c_validator.split(X, Y):
                    model = LDA()
                    model.fit(X[train, :], Y[train])
                    tmp = np.mean(model.predict(X[test]) == Y[test])
                    test_results.append(tmp)

                lda_palatability[i, j] = np.mean(test_results)

                # Linear Discriminant analysis for identity
                Y = identity[j, 0, t]
                test_results = []
                c_validator = LeavePOut(1)
                for train, test in c_validator.split(X, Y):
                    model = LDA()
                    model.fit(X[train, :], Y[train])
                    tmp = np.mean(model.predict(X[test]) == Y[test])
                    test_results.append(tmp)

                lda_identity[i, j] = np.mean(test_results)

                # Pairwise Identity Calculation
                for ti1, r1 in dim.iterrows():
                    for ti2, r2 in dim.iterrows():
                        t1 = r1.channel
                        t2 = r2.channel
                        tmp_trials = np.where((identity[j, 0, :] == t1) |
                                              (identity[j, 0, :] == t2))[0]
                        idx = [trial for trial in t if trial in tmp_trials]
                        X = response[j, :, idx]
                        Y = identity[j, 0, idx]
                        test_results = []
                        c_validator = StratifiedShuffleSplit(n_splits=10,
                                                             test_size=0.25,
                                                             random_state=0)
                        for train, test in c_validator.split(X, Y):
                            model = GaussianNB()
                            model.fit(X[train, :], Y[train])
                            tmp_score = model.score(X[test, :], Y[test])
                            test_results.append(tmp_score)

                        pairwise_identity[i, j, ti1, ti2] = np.mean(test_results)

        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;r_pearson&#39;, r_pearson)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;r_spearman&#39;, r_spearman)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;p_pearson&#39;, p_pearson)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;p_spearman&#39;, p_spearman)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;lda_palatability&#39;, lda_palatability)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;lda_identity&#39;, lda_identity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;r_isotonic&#39;, r_isotonic)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;id_pal_regress&#39;, id_pal_regress)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;f_identity&#39;, f_identity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;p_identity&#39;, p_identity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;pairwise_NB_identity&#39;, pairwise_identity)
        hf5.flush()

    warnings.filterwarnings(&#39;default&#39;, category=UserWarning)
    warnings.filterwarnings(&#39;default&#39;, category=RuntimeWarning)


def palatability_rank_order_deduction(rec_dir, response, lasers, time, window):
    num_conditions = response.shape[0]
    num_tastes = response.shape[2]
    num_units = response.shape[3]
    num_trials = response.shape[4]
    if num_tastes == 3:
        base_p_patterns = [[1, 1, 1], [1, 1, 2], [1, 2, 2], [1, 2, 3]]
    elif num_tastes == 4:
        base_p_patterns = [[1, 1, 1, 1], [1, 1, 1, 2], [1, 1, 2, 2],
                           [1, 1, 2, 3], [1, 2, 2, 3], [1, 2, 3, 4]]

    save_file = os.path.join(rec_dir, &#39;palatability_deduction.txt&#39;)
    with open(save_file, &#39;w&#39;) as f:
        idx = np.where((time &gt;= window[0]) &amp; (time &lt;= window[1]))[0]
        for i, ul in enumerate(lasers):
            print(&#39;Laser Condition: %s&#39; % ul, file=f)
            for pattern in base_p_patterns:
                order = []
                corrs = []
                for per in itertools.permutations(pattern):
                    order.append(per)
                    this_corr = []
                    for j in range(num_units):
                        resp = np.mean(response[i, idx, :, j, :], axis=0)
                        resp = resp.T.reshape(-1)
                        comp = np.tile(per, num_trials)
                        tmp = pearsonr(resp, comp)[0]**2
                        this_corr.append(tmp)

                    corrs.append(np.mean(this_corr))

                max_order = order[np.argmax(corrs)]
                print(&#39;Base pattern: %s, Max pattern: %s, Max avg corr: %g&#39;
                      % (pattern, max_order, np.max(corrs)), file=f)

            print(&#34;&#34;, file=f)


def get_palatability_ranks(dig_in_mapping, shell=True):
    &#39;&#39;&#39;Queries user for palatability rankings for digital inputs (tastants) and
    adds a column to dig_in_mapping DataFrame

    Parameters
    ----------
    dig_in_mapping: pandas.DataFrame,
        DataFrame with at least columns &#39;channel&#39; and &#39;name&#39;, for mapping
        digital input channel number to a str name
    &#39;&#39;&#39;
    dim = dig_in_mapping.copy()
    tmp = dict.fromkeys(dim[&#39;name&#39;], 0)
    filler = userIO.dictIO(tmp, shell=shell)
    tmp = filler.fill_dict(&#39;Rank Palatability\n1 for the lowest\n&#39;
                           &#39;Leave blank to exclude from palatability analysis&#39;)
    dim[&#39;palatability_rank&#39;] = dim[&#39;name&#39;].map(tmp)
    return dim</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="blechpy.analysis.palatability_analysis.get_palatability_ranks"><code class="name flex">
<span>def <span class="ident">get_palatability_ranks</span></span>(<span>dig_in_mapping, shell=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Queries user for palatability rankings for digital inputs (tastants) and
adds a column to dig_in_mapping DataFrame</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dig_in_mapping</code></strong> :&ensp;<code>pandas.DataFrame,</code></dt>
<dd>DataFrame with at least columns 'channel' and 'name', for mapping
digital input channel number to a str name</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_palatability_ranks(dig_in_mapping, shell=True):
    &#39;&#39;&#39;Queries user for palatability rankings for digital inputs (tastants) and
    adds a column to dig_in_mapping DataFrame

    Parameters
    ----------
    dig_in_mapping: pandas.DataFrame,
        DataFrame with at least columns &#39;channel&#39; and &#39;name&#39;, for mapping
        digital input channel number to a str name
    &#39;&#39;&#39;
    dim = dig_in_mapping.copy()
    tmp = dict.fromkeys(dim[&#39;name&#39;], 0)
    filler = userIO.dictIO(tmp, shell=shell)
    tmp = filler.fill_dict(&#39;Rank Palatability\n1 for the lowest\n&#39;
                           &#39;Leave blank to exclude from palatability analysis&#39;)
    dim[&#39;palatability_rank&#39;] = dim[&#39;name&#39;].map(tmp)
    return dim</code></pre>
</details>
</dd>
<dt id="blechpy.analysis.palatability_analysis.palatability_identity_calculations"><code class="name flex">
<span>def <span class="ident">palatability_identity_calculations</span></span>(<span>rec_dir, pal_ranks=None, params=None, shell=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def palatability_identity_calculations(rec_dir, pal_ranks=None,
                                       params=None, shell=False):
    warnings.filterwarnings(&#39;ignore&#39;, category=UserWarning)
    warnings.filterwarnings(&#39;ignore&#39;, category=RuntimeWarning)
    dat = load_dataset(rec_dir)
    dim = dat.dig_in_mapping
    if &#39;palatability_rank&#39; in dim.columns:
        pass
    elif pal_ranks is None:
        dim = get_palatability_ranks(dim, shell=shell)
    else:
        dim[&#39;palatability_rank&#39;] = dim[&#39;name&#39;].map(pal_ranks)

    dim = dim.dropna(subset=[&#39;palatability_rank&#39;])
    dim = dim[dim[&#39;palatability_rank&#39;] &gt; 0]
    dim = dim.reset_index(drop=True)
    num_tastes = len(dim)
    taste_names = dim.name.to_list()

    trial_list = dat.dig_in_trials.copy()
    trial_list = trial_list[[True if x in taste_names else False
                             for x in trial_list.name]]
    num_trials = trial_list.groupby(&#39;channel&#39;).count()[&#39;name&#39;].unique()
    if len(num_trials) &gt; 1:
        raise ValueError(&#39;Unequal number of trials for tastes to used&#39;)
    else:
        num_trials = num_trials[0]

    dim[&#39;num_trials&#39;] = num_trials

    # Get which units to use
    unit_table = h5io.get_unit_table(rec_dir)
    unit_types = [&#39;Single&#39;, &#39;Multi&#39;, &#39;All&#39;, &#39;Custom&#39;]
    unit_type = params.get(&#39;unit_type&#39;)
    if unit_type is None:
        q = userIO.ask_user(&#39;Which units do you want to use for taste &#39;
                            &#39;discrimination and  palatability analysis?&#39;,
                            choices=unit_types,
                            shell=shell)
        unit_type = unit_types[q]

    if unit_type == &#39;Single&#39;:
        chosen_units = unit_table.loc[unit_table[&#39;single_unit&#39;],
                                      &#39;unit_num&#39;].to_list()
    elif unit_type == &#39;Multi&#39;:
        chosen_units = unit_table.loc[unit_table[&#39;single_unit&#39;] == False,
                                      &#39;unit_num&#39;].to_list()
    elif unit_type == &#39;All&#39;:
        chosen_units = unit_table[&#39;unit_num&#39;].to_list()
    else:
        selection = userIO.select_from_list(&#39;Select units to use:&#39;,
                                            unit_table[&#39;unit_num&#39;],
                                            &#39;Select Units&#39;,
                                            multi_select=True)
        chosen_units = list(map(int, selection))

    num_units = len(chosen_units)
    unit_table = unit_table.loc[chosen_units]

    # Enter Parameters
    if params is None or params.keys() != default_pal_id_params.keys():
        params = default_pal_id_params.copy()
        params = userIO.confirm_parameter_dict(params,
                                               (&#39;Palatability/Identity &#39;
                                                &#39;Calculation Parameters&#39;
                                                &#39;\nTimes in ms&#39;), shell=shell)

    win_size = params[&#39;window_size&#39;]
    win_step = params[&#39;window_step&#39;]
    print(&#39;Running palatability/identity calculations with parameters:\n%s&#39; %
          pt.print_dict(params))

    with tables.open_file(dat.h5_file, &#39;r+&#39;) as hf5:
        trains_dig_in = hf5.list_nodes(&#39;/spike_trains&#39;)
        time = trains_dig_in[0].array_time[:]
        bin_times = np.arange(time[0], time[-1] - win_size + win_step,
                             win_step)
        num_bins = len(bin_times)

        palatability = np.empty((num_bins, num_units, num_tastes*num_trials),
                                dtype=int)
        identity = np.empty((num_bins, num_units, num_tastes*num_trials),
                            dtype=int)
        unscaled_response = np.empty((num_bins, num_units, num_tastes*num_trials),
                                     dtype=np.dtype(&#39;float64&#39;))
        response  = np.empty((num_bins, num_units, num_tastes*num_trials),
                             dtype=np.dtype(&#39;float64&#39;))
        laser = np.empty((num_bins, num_units, num_tastes*num_trials, 2),
                         dtype=float)

        # Fill arrays with data
        print(&#39;Filling data arrays...&#39;)
        onesies = np.ones((num_bins, num_units, num_trials))
        for i, row in dim.iterrows():
            idx = range(num_trials*i, num_trials*(i+1))
            palatability[:, :, idx] = row.palatability_rank * onesies
            identity[:, :, idx] = row.channel * onesies
            for j, u in enumerate(chosen_units):
                for k,t in enumerate(bin_times):
                    t_idx = np.where((time &gt;= t) &amp; (time &lt;= t+win_size))[0]
                    unscaled_response[k, j, idx] = \
                            np.mean(trains_dig_in[i].spike_array[:, u, t_idx],
                                    axis=1)
                    try:
                        lasers[k, j, idx] = \
                            np.vstack((trains_dig_in[i].laser_durations[:],
                                       trains_dig_in[i].laser_onset_lag[:]))
                    except:
                        laser[k, j, idx] = np.zeros((num_trials, 2))

        # Scaling was not done, so:
        response = unscaled_response.copy()

        # Make ancillary_analysis node and put in arrays
        if &#39;/ancillary_analysis&#39; in hf5:
            hf5.remove_node(&#39;/ancillary_analysis&#39;, recursive=True)

        hf5.create_group(&#39;/&#39;, &#39;ancillary_analysis&#39;)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;palatability&#39;, palatability)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;identity&#39;, identity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;laser&#39;, laser)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;scaled_neural_response&#39;,
                         response)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;window_params&#39;,
                         np.array([win_size, win_step]))
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;bin_times&#39;, bin_times)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;unscaled_neural_response&#39;,
                         unscaled_response)

        # for backwards compatibility
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;params&#39;,
                        np.array([win_size, win_step]))
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;pre_stim&#39;, np.array(time[0]))
        hf5.flush()

        # Get unique laser (duration, lag) combinations
        print(&#39;Organizing trial data...&#39;)
        unique_lasers = np.vstack(list({tuple(row) for row in laser[0, 0, :, :]}))
        unique_lasers = unique_lasers[unique_lasers[:, 1].argsort(), :]
        num_conditions = unique_lasers.shape[0]
        trials = []
        for row in unique_lasers:
            tmp_trials = [j for j in range(num_trials * num_tastes)
                          if np.array_equal(laser[0, 0, j, :], row)]
            trials.append(tmp_trials)

        trials_per_condition = [len(x) for x in trials]
        if not all(x == trials_per_condition[0] for x in trials_per_condition):
            raise ValueError(&#39;Different number of trials for each laser condition&#39;)

        trials_per_condition = int(trials_per_condition[0] / num_tastes)  #assumes same number of trials per taste per condition
        print(&#39;Detected:\n    %i tastes\n    %i laser conditions\n&#39;
              &#39;    %i trials per condition per taste&#39; %
              (num_tastes, num_conditions, trials_per_condition))
        trials = np.array(trials)

        # Store laser conditions and indices of trials per condition in trial x
        # taste space
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;trials&#39;, trials)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;laser_combination_d_l&#39;,
                         unique_lasers)
        hf5.flush()

        # Taste Similarity Calculation
        neural_response_laser = np.empty((num_conditions, num_bins,
                                          num_tastes, num_units,
                                          trials_per_condition),
                                         dtype=np.dtype(&#39;float64&#39;))
        taste_cosine_similarity = np.empty((num_conditions, num_bins,
                                            num_tastes, num_tastes),
                                           dtype=np.dtype(&#39;float64&#39;))
        taste_euclidean_distance = np.empty((num_conditions, num_bins,
                                             num_tastes, num_tastes),
                                            dtype=np.dtype(&#39;float64&#39;))

        # Re-format neural responses from bin x unit x (trial*taste) to
        # laser_condition x bin x taste x unit x trial
        print(&#39;Reformatting data arrays...&#39;)
        for i, trial in enumerate(trials):
            for j, _ in enumerate(bin_times):
                for k, _ in dim.iterrows():
                    idx = np.where((trial &gt;= num_trials*k) &amp;
                                   (trial &lt; num_trials*(k+1)))[0]
                    neural_response_laser[i, j, k, :, :] = \
                            response[j, :, trial[idx]].T

        # Compute taste cosine similarity and euclidean distances
        print(&#39;Computing taste cosine similarity and euclidean distances...&#39;)
        for i, _ in enumerate(trials):
            for j, _ in enumerate(bin_times):
                for k, _ in dim.iterrows():
                    for l, _ in dim.iterrows():
                        taste_cosine_similarity[i, j, k, l] = \
                                np.mean(cosine_similarity(
                                    neural_response_laser[i, j, k, :, :].T,
                                    neural_response_laser[i, j, l, :, :].T))
                        taste_euclidean_distance[i, j, k, l] = \
                                np.mean(cdist(
                                    neural_response_laser[i, j, k, :, :].T,
                                    neural_response_laser[i, j, l, :, :].T,
                                    metric=&#39;euclidean&#39;))

        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_cosine_similarity&#39;,
                         taste_cosine_similarity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_euclidean_distance&#39;,
                         taste_euclidean_distance)
        hf5.flush()

        # Taste Responsiveness calculations
        bin_params = [params[&#39;num_comparison_bins&#39;],
                      params[&#39;comparison_bin_size&#39;]]
        discrim_p = params[&#39;discrim_p&#39;]

        responsive_neurons = []
        discriminating_neurons = []
        taste_responsiveness = np.zeros((bin_params[0], num_units, 2))
        new_bin_times = np.arange(0, np.prod(bin_params), bin_params[1])
        baseline = np.where(bin_times &lt; 0)[0]
        print(&#39;Computing taste responsiveness and taste discrimination...&#39;)
        for i, t in enumerate(new_bin_times):
            places = np.where((bin_times &gt;= t) &amp;
                              (bin_times &lt;= t+bin_params[1]))[0]
            for j, u in enumerate(chosen_units):
                # Check taste responsiveness
                f, p = f_oneway(np.mean(response[places, j, :], axis=0),
                                np.mean(response[baseline, j, :], axis=0))
                if np.isnan(f):
                    f = 0.0
                    p = 1.0

                if p &lt;= discrim_p and u not in responsive_neurons:
                    responsive_neurons.append(u)
                    taste_responsiveness[i, j, 0] = 1

                # Check taste discrimination
                taste_idx = [np.arange(num_trials*k, num_trials*(k+1))
                             for k in range(num_tastes)]
                taste_responses = [np.mean(response[places, j, :][:, k], axis=0)
                                   for k in taste_idx]
                f, p = f_oneway(*taste_responses)
                if np.isnan(f):
                    f = 0.0
                    p = 1.0

                if p &lt;= discrim_p and u not in discriminating_neurons:
                    discriminating_neurons.append(u)

        responsive_neurons = np.sort(responsive_neurons)
        discriminating_neurons = np.sort(discriminating_neurons)

        # Write taste responsive and taste discriminating units to text file
        save_file = os.path.join(rec_dir, &#39;discriminative_responsive_neurons.txt&#39;)
        with open(save_file, &#39;w&#39;) as f:
            print(&#39;Taste discriminative neurons&#39;, file=f)
            for u in discriminating_neurons:
                print(u, file=f)

            print(&#39;Taste responsive neurons&#39;, file=f)
            for u in responsive_neurons:
                print(u, file=f)

        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_disciminating_neurons&#39;,
                         discriminating_neurons)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_responsive_neurons&#39;,
                         responsive_neurons)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;taste_responsiveness&#39;,
                         taste_responsiveness)
        hf5.flush()

        # Get time course of taste discrimibility
        print(&#39;Getting taste discrimination time course...&#39;)
        p_discrim = np.empty((num_conditions, num_bins, num_tastes, num_tastes,
                              num_units), dtype=np.dtype(&#39;float64&#39;))
        for i in range(num_conditions):
            for j, t in enumerate(bin_times):
                for k in range(num_tastes):
                    for l in range(num_tastes):
                        for m in range(num_units):
                            _, p = ttest_ind(neural_response_laser[i, j, k, m, :],
                                             neural_response_laser[i, j, l, m, :],
                                             equal_var = False)
                            if np.isnan(p):
                                p = 1.0

                            p_discrim[i, j, k, l, m] = p

        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;p_discriminability&#39;,
                          p_discrim)
        hf5.flush()

        # Palatability Rank Order calculation (if &gt; 2 tastes)
        t_start = params[&#39;pal_deduce_start_time&#39;]
        t_end = params[&#39;pal_deduce_end_time&#39;]
        if num_tastes &gt; 2:
            print(&#39;Deducing palatability rank order...&#39;)
            palatability_rank_order_deduction(rec_dir, neural_response_laser,
                                              unique_lasers,
                                              bin_times, [t_start, t_end])

        # Palatability calculation
        r_spearman = np.zeros((num_conditions, num_bins, num_units))
        p_spearman = np.ones((num_conditions, num_bins, num_units))
        r_pearson = np.zeros((num_conditions, num_bins, num_units))
        p_pearson = np.ones((num_conditions, num_bins, num_units))
        f_identity = np.ones((num_conditions, num_bins, num_units))
        p_identity = np.ones((num_conditions, num_bins, num_units))
        lda_palatability = np.zeros((num_conditions, num_bins))
        lda_identity = np.zeros((num_conditions, num_bins))
        r_isotonic = np.zeros((num_conditions, num_bins, num_units))
        id_pal_regress = np.zeros((num_conditions, num_bins, num_units, 2))
        pairwise_identity = np.zeros((num_conditions, num_bins, num_tastes, num_tastes))
        print(&#39;Computing palatability metrics...&#39;)

        for i, t in enumerate(trials):
            for j in range(num_bins):
                for k in range(num_units):
                    ranks = rankdata(response[j, k, t])
                    r_spearman[i, j, k], p_spearman[i, j, k] = \
                            spearmanr(ranks, palatability[j, k, t])
                    r_pearson[i, j, k], p_pearson[i, j, k] = \
                            pearsonr(response[j, k, t], palatability[j, k, t])
                    if np.isnan(r_spearman[i, j, k]):
                        r_spearman[i, j, k] = 0.0
                        p_spearman[i, j, k] = 1.0

                    if np.isnan(r_pearson[i, j, k]):
                        r_pearson[i, j, k] = 0.0
                        p_pearson[i, j, k] = 1.0

                    # Isotonic regression of firing against palatability
                    model = IsotonicRegression(increasing = &#39;auto&#39;)
                    model.fit(palatability[j, k, t], response[j, k, t])
                    r_isotonic[i, j, k] = model.score(palatability[j, k, t],
                                                      response[j, k, t])

                    # Multiple Regression of firing rate against palatability and identity
                    # Regress palatability on identity
                    tmp_id = identity[j, k, t].reshape(-1, 1)
                    tmp_pal = palatability[j, k, t].reshape(-1, 1)
                    tmp_resp = response[j, k, t].reshape(-1, 1)
                    model_pi = LinearRegression()
                    model_pi.fit(tmp_id, tmp_pal)
                    pi_residuals = tmp_pal - model_pi.predict(tmp_id)

                    # Regress identity on palatability
                    model_ip = LinearRegression()
                    model_ip.fit(tmp_pal, tmp_id)
                    ip_residuals = tmp_id - model_ip.predict(tmp_pal)

                    # Regress firing on identity
                    model_fi = LinearRegression()
                    model_fi.fit(tmp_id, tmp_resp)
                    fi_residuals = tmp_resp - model_fi.predict(tmp_id)

                    # Regress firing on palatability
                    model_fp = LinearRegression()
                    model_fp.fit(tmp_pal, tmp_resp)
                    fp_residuals = tmp_resp - model_fp.predict(tmp_pal)

                    # Get partial correlation coefficient of response with identity
                    idp_reg0, p = pearsonr(fp_residuals, ip_residuals)
                    if np.isnan(idp_reg0):
                        idp_reg0 = 0.0

                    idp_reg1, p = pearsonr(fi_residuals, pi_residuals)
                    if np.isnan(idp_reg1):
                        idp_reg1 = 0.0

                    id_pal_regress[i, j, k, 0] = idp_reg0
                    id_pal_regress[i, j, k, 1] = idp_reg1

                    # Identity Calculation
                    samples = []
                    for _, row in dim.iterrows():
                        taste = row.channel
                        samples.append([trial for trial in t
                                        if identity[j, k, trial] == taste])

                    tmp_resp = [response[j, k, sample] for sample in samples]
                    f_identity[i, j, k], p_identity[i, j, k] = f_oneway(*tmp_resp)
                    if np.isnan(f_identity[i, j, k]):
                        f_identity[i, j, k] = 0.0
                        p_identity[i, j, k] = 1.0


                # Linear Discriminant analysis for palatability
                X = response[j, :, t]
                Y = palatability[j, 0, t]
                test_results = []
                c_validator = LeavePOut(1)
                for train, test in c_validator.split(X, Y):
                    model = LDA()
                    model.fit(X[train, :], Y[train])
                    tmp = np.mean(model.predict(X[test]) == Y[test])
                    test_results.append(tmp)

                lda_palatability[i, j] = np.mean(test_results)

                # Linear Discriminant analysis for identity
                Y = identity[j, 0, t]
                test_results = []
                c_validator = LeavePOut(1)
                for train, test in c_validator.split(X, Y):
                    model = LDA()
                    model.fit(X[train, :], Y[train])
                    tmp = np.mean(model.predict(X[test]) == Y[test])
                    test_results.append(tmp)

                lda_identity[i, j] = np.mean(test_results)

                # Pairwise Identity Calculation
                for ti1, r1 in dim.iterrows():
                    for ti2, r2 in dim.iterrows():
                        t1 = r1.channel
                        t2 = r2.channel
                        tmp_trials = np.where((identity[j, 0, :] == t1) |
                                              (identity[j, 0, :] == t2))[0]
                        idx = [trial for trial in t if trial in tmp_trials]
                        X = response[j, :, idx]
                        Y = identity[j, 0, idx]
                        test_results = []
                        c_validator = StratifiedShuffleSplit(n_splits=10,
                                                             test_size=0.25,
                                                             random_state=0)
                        for train, test in c_validator.split(X, Y):
                            model = GaussianNB()
                            model.fit(X[train, :], Y[train])
                            tmp_score = model.score(X[test, :], Y[test])
                            test_results.append(tmp_score)

                        pairwise_identity[i, j, ti1, ti2] = np.mean(test_results)

        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;r_pearson&#39;, r_pearson)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;r_spearman&#39;, r_spearman)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;p_pearson&#39;, p_pearson)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;p_spearman&#39;, p_spearman)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;lda_palatability&#39;, lda_palatability)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;lda_identity&#39;, lda_identity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;r_isotonic&#39;, r_isotonic)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;id_pal_regress&#39;, id_pal_regress)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;f_identity&#39;, f_identity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;p_identity&#39;, p_identity)
        hf5.create_array(&#39;/ancillary_analysis&#39;, &#39;pairwise_NB_identity&#39;, pairwise_identity)
        hf5.flush()

    warnings.filterwarnings(&#39;default&#39;, category=UserWarning)
    warnings.filterwarnings(&#39;default&#39;, category=RuntimeWarning)</code></pre>
</details>
</dd>
<dt id="blechpy.analysis.palatability_analysis.palatability_rank_order_deduction"><code class="name flex">
<span>def <span class="ident">palatability_rank_order_deduction</span></span>(<span>rec_dir, response, lasers, time, window)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def palatability_rank_order_deduction(rec_dir, response, lasers, time, window):
    num_conditions = response.shape[0]
    num_tastes = response.shape[2]
    num_units = response.shape[3]
    num_trials = response.shape[4]
    if num_tastes == 3:
        base_p_patterns = [[1, 1, 1], [1, 1, 2], [1, 2, 2], [1, 2, 3]]
    elif num_tastes == 4:
        base_p_patterns = [[1, 1, 1, 1], [1, 1, 1, 2], [1, 1, 2, 2],
                           [1, 1, 2, 3], [1, 2, 2, 3], [1, 2, 3, 4]]

    save_file = os.path.join(rec_dir, &#39;palatability_deduction.txt&#39;)
    with open(save_file, &#39;w&#39;) as f:
        idx = np.where((time &gt;= window[0]) &amp; (time &lt;= window[1]))[0]
        for i, ul in enumerate(lasers):
            print(&#39;Laser Condition: %s&#39; % ul, file=f)
            for pattern in base_p_patterns:
                order = []
                corrs = []
                for per in itertools.permutations(pattern):
                    order.append(per)
                    this_corr = []
                    for j in range(num_units):
                        resp = np.mean(response[i, idx, :, j, :], axis=0)
                        resp = resp.T.reshape(-1)
                        comp = np.tile(per, num_trials)
                        tmp = pearsonr(resp, comp)[0]**2
                        this_corr.append(tmp)

                    corrs.append(np.mean(this_corr))

                max_order = order[np.argmax(corrs)]
                print(&#39;Base pattern: %s, Max pattern: %s, Max avg corr: %g&#39;
                      % (pattern, max_order, np.max(corrs)), file=f)

            print(&#34;&#34;, file=f)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="blechpy.analysis" href="index.html">blechpy.analysis</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="blechpy.analysis.palatability_analysis.get_palatability_ranks" href="#blechpy.analysis.palatability_analysis.get_palatability_ranks">get_palatability_ranks</a></code></li>
<li><code><a title="blechpy.analysis.palatability_analysis.palatability_identity_calculations" href="#blechpy.analysis.palatability_analysis.palatability_identity_calculations">palatability_identity_calculations</a></code></li>
<li><code><a title="blechpy.analysis.palatability_analysis.palatability_rank_order_deduction" href="#blechpy.analysis.palatability_analysis.palatability_rank_order_deduction">palatability_rank_order_deduction</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>